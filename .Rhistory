Marriott.list <- searchTwitter('#Marriott', n=1000, cainfo="cacert.pem")
require(twitteR)
library(ROAuth)
library(plyr)
library(stringr)
library(ggplot2)
download.file(url="http://curl.haxx.se/ca/cacert.pem", destfile="cacert.pem")
requestURL <-"https://api.twitter.com/oauth/request_token"
accessURL <- "https://api.twitter.com/oauth/access_token"
authURL <- "https://api.twitter.com/oauth/authorize"
consumerKey = "02Ph1HDIG49W0whP76pzEbA5k"
consumerSecret = "O4yG0VUPz7Mo3l30YGQTPpC2DrGVKyotZqPezLQv2bBtIjdNZV"
Cred <- OAuthFactory$new(consumerKey=consumerKey,
consumerSecret=consumerSecret,
requestURL=requestURL,
accessURL=accessURL,
authURL=authURL)
Cred$handshake(cainfo = system.file("CurlSSL", "cacert.pem", package = "RCurl") )
Cred <- OAuthFactory$new(consumerKey=consumerKey,
consumerSecret=consumerSecret,
requestURL=requestURL,
accessURL=accessURL,
authURL=authURL)
Cred$handshake(cainfo = system.file("CurlSSL", "cacert.pem", package = "RCurl") )
# Comments: This is a very important step; you need to copy the url and #paste to internet browser, then copy the code to R, follow the video to #complete this step.
save(Cred, file="twitter authentication.Rdata")
registerTwitterOAuth(Cred)
Path = 'C:/MyHWP/TP/20141020/CBA1C05 - Social Media Analytics/Assignment/'
Marriott.list <- searchTwitter('#Marriott', n=1000, cainfo="cacert.pem")
Marriott.list <- searchTwitter('#Marriott American', n=1000, cainfo="cacert.pem")
Marriott.list <- searchTwitter('#Marriott USA', n=1000, cainfo="cacert.pem")
Marriott.list <- searchTwitter('#Marriott Worldwide', n=1000, cainfo="cacert.pem")
require(twitteR)
library(ROAuth)
library(plyr)
library(stringr)
library(ggplot2)
download.file(url="http://curl.haxx.se/ca/cacert.pem", destfile="cacert.pem")
requestURL <-"https://api.twitter.com/oauth/request_token"
accessURL <- "https://api.twitter.com/oauth/access_token"
authURL <- "https://api.twitter.com/oauth/authorize"
consumerKey = "02Ph1HDIG49W0whP76pzEbA5k"
consumerSecret = "O4yG0VUPz7Mo3l30YGQTPpC2DrGVKyotZqPezLQv2bBtIjdNZV"
Cred <- OAuthFactory$new(consumerKey=consumerKey,
consumerSecret=consumerSecret,
requestURL=requestURL,
accessURL=accessURL,
authURL=authURL)
Cred$handshake(cainfo = system.file("CurlSSL", "cacert.pem", package = "RCurl") )
# Comments: This is a very important step; you need to copy the url and #paste to internet browser, then copy the code to R, follow the video to #complete this step.
save(Cred, file="twitter authentication.Rdata")
registerTwitterOAuth(Cred)
############################################################
# Chunk  - 2 - Twitter Scrape  #Marriott #Hilton #
############################################################
Path = 'C:/MyHWP/TP/20141020/CBA1C05 - Social Media Analytics/Assignment/'
Marriott.list <- searchTwitter('#Marriott', n=1000, cainfo="cacert.pem")
# Comments: Mining 1000 tweets of ???Marriott ???, you might not get 1000 tweets
Marriott.df = twListToDF(Marriott.list)
write.csv(Marriott.df, file=paste(Path,"MarriottTweets.csv",sep=""), row.names=F)
# Comments: export data to your own path
Hilton.list <- searchTwitter('#Hilton', n=1000, cainfo="cacert.pem")
# Comments: Mining 1000 tweets of ???Hilton???
Hilton.df = twListToDF(Hilton.list)
write.csv(Hilton.df, file=paste(Path,"HiltonTweets.csv",sep=""), row.names=F)
# Comments: export data to your own path
###############################
# Sentiment Function
###############################
library (plyr)
library (stringr)
score.sentiment = function(sentences, pos.words, neg.words, .progress='none')
{
require(plyr)
require(stringr)
scores=laply(sentences, function(sentence, pos.words, neg.words){
sentence = gsub('[[:punct:]]', '', sentence)
sentence = gsub('[[:cntrl:]]', '', sentence)
sentence = gsub('\\d+', '', sentence)
sentence = tolower(sentence)
word.list = str_split(sentence, '\\s+')
words = unlist(word.list)
pos.matches = match(words, pos.words)
neg.matches = match(words, neg.words)
pos.matches = !is.na(pos.matches)
neg.matches = !is.na(neg.matches)
score = sum(pos.matches) - sum(neg.matches)
return(score)
}, pos.words, neg.words, .progress=.progress)
scores.df = data.frame(score=scores, text=sentences)
return(scores.df)
}
############################################
# Scoring Tweets &amp; Adding a column
############################################
#Load sentiment word lists
hu.liu.pos = scan('C:/MyHWP/TP/20141020/CBA1C05 - Social Media Analytics/Assignment/positive-words.txt', what='character', comment.char=';')
hu.liu.neg = scan('C:/MyHWP/TP/20141020/CBA1C05 - Social Media Analytics/Assignment/negative-words.txt', what='character', comment.char=';')
#Add words to list
pos.words = hu.liu.pos
neg.words = hu.liu.neg
#Import 2 csv
DatasetMarriott <- read.csv("C:/MyHWP/TP/20141020/CBA1C05 - Social Media Analytics/Assignment/MarriottTweets.csv")
DatasetMarriott$text<-as.factor(DatasetMarriott$text)
DatasetHilton <- read.csv("C:/MyHWP/TP/20141020/CBA1C05 - Social Media Analytics/Assignment/HiltonTweets.csv")
DatasetHilton$text<-as.factor(DatasetHilton$text)
#Score all tweets from Marriott Hotel
Marriott.scores = score.sentiment(DatasetMarriott$text, pos.words,neg.words, .progress='text')
#Score all tweets from Hilton Hotel
Hilton.scores = score.sentiment(DatasetHilton$text, pos.words,neg.words, .progress='text')
#Export scores to csv file
path<-"C:/MyHWP/TP/20141020/CBA1C05 - Social Media Analytics/Assignment/"
write.csv(Marriott.scores,file=paste(path,"MarriottScores.csv",sep=""),row.names=TRUE)
write.csv(Hilton.scores,file=paste(path,"HiltonScores.csv",sep=""),row.names=TRUE)
Marriott.scores$Team = 'Marriott'
Hilton.scores$Team = 'Hilton'
#############################
# Visualizing
#############################
library(ggplot2)
hist(Marriott.scores$score)
qplot(Marriott.scores$score)
hist(Hilton.scores$score)
qplot(Hilton.scores$score)
#################################
# Comparing 2 datasets
#################################
all.scores = rbind(Marriott.scores, Hilton.scores)
table(all.scores$score,all.scores$Team)
ggplot(data=all.scores) + # ggplot works on data.frames, always
geom_bar(mapping=aes(x=score, fill=Team), binwidth=1) +
facet_grid(Team~.) + # make a separate plot for each hashtag
theme_bw() + scale_fill_brewer() # plain display, nicer colors
require(twitteR)
library(ROAuth)
library(plyr)
library(stringr)
library(ggplot2)
download.file(url="http://curl.haxx.se/ca/cacert.pem", destfile="cacert.pem")
requestURL <-"https://api.twitter.com/oauth/request_token"
accessURL <- "https://api.twitter.com/oauth/access_token"
authURL <- "https://api.twitter.com/oauth/authorize"
consumerKey = "02Ph1HDIG49W0whP76pzEbA5k"
consumerSecret = "O4yG0VUPz7Mo3l30YGQTPpC2DrGVKyotZqPezLQv2bBtIjdNZV"
Cred <- OAuthFactory$new(consumerKey=consumerKey,
consumerSecret=consumerSecret,
requestURL=requestURL,
accessURL=accessURL,
authURL=authURL)
Cred$handshake(cainfo = system.file("CurlSSL", "cacert.pem", package = "RCurl") )
Cred$handshake(cainfo = system.file("CurlSSL", "cacert.pem", package = "RCurl") )
save(Cred, file="twitter authentication.Rdata")
registerTwitterOAuth(Cred)
Path = 'C:/MyHWP/TP/20141020/CBA1C05 - Social Media Analytics/Assignment/'
Marriott.list <- searchTwitter('#Marriott', n=1000, cainfo="cacert.pem")
# Comments: Mining 1000 tweets of ???Marriott ???, you might not get 1000 tweets
Marriott.df = twListToDF(Marriott.list)
write.csv(Marriott.df, file=paste(Path,"MarriottTweets.csv",sep=""), row.names=F)
# Comments: export data to your own path
Hilton.list <- searchTwitter('#Hilton', n=1000, cainfo="cacert.pem")
# Comments: Mining 1000 tweets of ???Hilton???
Hilton.df = twListToDF(Hilton.list)
write.csv(Hilton.df, file=paste(Path,"HiltonTweets.csv",sep=""), row.names=F)
# Comments: export data to your own path
###############################
# Sentiment Function
###############################
library (plyr)
library (stringr)
score.sentiment = function(sentences, pos.words, neg.words, .progress='none')
{
require(plyr)
require(stringr)
scores=laply(sentences, function(sentence, pos.words, neg.words){
sentence = gsub('[[:punct:]]', '', sentence)
sentence = gsub('[[:cntrl:]]', '', sentence)
sentence = gsub('\\d+', '', sentence)
sentence = tolower(sentence)
word.list = str_split(sentence, '\\s+')
words = unlist(word.list)
pos.matches = match(words, pos.words)
neg.matches = match(words, neg.words)
pos.matches = !is.na(pos.matches)
neg.matches = !is.na(neg.matches)
score = sum(pos.matches) - sum(neg.matches)
return(score)
}, pos.words, neg.words, .progress=.progress)
scores.df = data.frame(score=scores, text=sentences)
return(scores.df)
}
############################################
# Scoring Tweets &amp; Adding a column
############################################
#Load sentiment word lists
hu.liu.pos = scan('C:/MyHWP/TP/20141020/CBA1C05 - Social Media Analytics/Assignment/positive-words.txt', what='character', comment.char=';')
hu.liu.neg = scan('C:/MyHWP/TP/20141020/CBA1C05 - Social Media Analytics/Assignment/negative-words.txt', what='character', comment.char=';')
#Add words to list
pos.words = hu.liu.pos
neg.words = hu.liu.neg
#Import 2 csv
DatasetMarriott <- read.csv("C:/MyHWP/TP/20141020/CBA1C05 - Social Media Analytics/Assignment/MarriottTweets.csv")
DatasetMarriott$text<-as.factor(DatasetMarriott$text)
DatasetHilton <- read.csv("C:/MyHWP/TP/20141020/CBA1C05 - Social Media Analytics/Assignment/HiltonTweets.csv")
DatasetHilton$text<-as.factor(DatasetHilton$text)
#Score all tweets from Marriott Hotel
Marriott.scores = score.sentiment(DatasetMarriott$text, pos.words,neg.words, .progress='text')
#Score all tweets from Hilton Hotel
Hilton.scores = score.sentiment(DatasetHilton$text, pos.words,neg.words, .progress='text')
#Export scores to csv file
path<-"C:/MyHWP/TP/20141020/CBA1C05 - Social Media Analytics/Assignment/"
write.csv(Marriott.scores,file=paste(path,"MarriottScores.csv",sep=""),row.names=TRUE)
write.csv(Hilton.scores,file=paste(path,"HiltonScores.csv",sep=""),row.names=TRUE)
Marriott.scores$Team = 'Marriott'
Hilton.scores$Team = 'Hilton'
#############################
# Visualizing
#############################
library(ggplot2)
hist(Marriott.scores$score)
qplot(Marriott.scores$score)
hist(Hilton.scores$score)
qplot(Hilton.scores$score)
#################################
# Comparing 2 datasets
#################################
all.scores = rbind(Marriott.scores, Hilton.scores)
table(all.scores$score,all.scores$Team)
ggplot(data=all.scores) + # ggplot works on data.frames, always
geom_bar(mapping=aes(x=score, fill=Team), binwidth=1) +
facet_grid(Team~.) + # make a separate plot for each hashtag
theme_bw() + scale_fill_brewer() # plain display, nicer colors
require(twitteR)
library(ROAuth)
library(plyr)
library(stringr)
library(ggplot2)
download.file(url="http://curl.haxx.se/ca/cacert.pem", destfile="cacert.pem")
requestURL <-"https://api.twitter.com/oauth/request_token"
accessURL <- "https://api.twitter.com/oauth/access_token"
authURL <- "https://api.twitter.com/oauth/authorize"
consumerKey = "02Ph1HDIG49W0whP76pzEbA5k"
consumerSecret = "O4yG0VUPz7Mo3l30YGQTPpC2DrGVKyotZqPezLQv2bBtIjdNZV"
Cred <- OAuthFactory$new(consumerKey=consumerKey,
consumerSecret=consumerSecret,
requestURL=requestURL,
accessURL=accessURL,
authURL=authURL)
Cred$handshake(cainfo = system.file("CurlSSL", "cacert.pem", package = "RCurl") )
# Comments: This is a very important step; you need to copy the url and #paste to internet browser, then copy the code to R, follow the video to #complete this step.
save(Cred, file="twitter authentication.Rdata")
registerTwitterOAuth(Cred)
############################################################
# Chunk  - 2 - Twitter Scrape  #Marriott #Hilton #
############################################################
Path = 'C:/MyHWP/TP/20141020/CBA1C05 - Social Media Analytics/Assignment/'
bizSAFE.list <- searchTwitter('#bizSAFE', n=1000, cainfo="cacert.pem")
# Comments: Mining 1000 tweets of ???bizSAFE???, you might not get 1000 tweets
bizSAFE.df = twListToDF(bizSAFE.list)
bizSAFE.list <- searchTwitter('#Construction', n=1000, cainfo="cacert.pem")
require(twitteR)
library(ROAuth)
library(plyr)
library(stringr)
library(ggplot2)
download.file(url="http://curl.haxx.se/ca/cacert.pem", destfile="cacert.pem")
requestURL <-"https://api.twitter.com/oauth/request_token"
accessURL <- "https://api.twitter.com/oauth/access_token"
authURL <- "https://api.twitter.com/oauth/authorize"
consumerKey = "02Ph1HDIG49W0whP76pzEbA5k"
consumerSecret = "O4yG0VUPz7Mo3l30YGQTPpC2DrGVKyotZqPezLQv2bBtIjdNZV"
Cred <- OAuthFactory$new(consumerKey=consumerKey,
consumerSecret=consumerSecret,
requestURL=requestURL,
accessURL=accessURL,
authURL=authURL)
Cred$handshake(cainfo = system.file("CurlSSL", "cacert.pem", package = "RCurl") )
requestURL=requestURL,4605987
Cred$handshake(cainfo = system.file("CurlSSL", "cacert.pem", package = "RCurl") )
# Comments: This is a very important step; you need to copy the url and #paste to internet browser, then copy the code to R, follow the video to #complete this step.
save(Cred, file="twitter authentication.Rdata")
registerTwitterOAuth(Cred)
############################################################
# Chunk  - 2 - Twitter Scrape  #Marriott #Hilton #
############################################################
Path = 'C:/Assignment/'
Facebook.list <- searchTwitter('#Facebook', n=1000, cainfo="cacert.pem")
# Comments: Mining 1000 tweets of ???Facebook???, you might not get 1000 tweets
Facebook.df = twListToDF(Facebook.list)
write.csv(Facebook.df, file=paste(Path,"FacebookTweets.csv",sep=""), row.names=F)
# Comments: export data to your own path
###############################
# Sentiment Function
###############################
library (plyr)
library (stringr)
score.sentiment = function(sentences, pos.words, neg.words, .progress='none')
{
require(plyr)
require(stringr)
scores=laply(sentences, function(sentence, pos.words, neg.words){
sentence = gsub('[[:punct:]]', '', sentence)
sentence = gsub('[[:cntrl:]]', '', sentence)
sentence = gsub('\\d+', '', sentence)
sentence = tolower(sentence)
word.list = str_split(sentence, '\\s+')
words = unlist(word.list)
pos.matches = match(words, pos.words)
neg.matches = match(words, neg.words)
pos.matches = !is.na(pos.matches)
neg.matches = !is.na(neg.matches)
score = sum(pos.matches) - sum(neg.matches)
return(score)
}, pos.words, neg.words, .progress=.progress)
scores.df = data.frame(score=scores, text=sentences)
return(scores.df)
}
############################################
# Scoring Tweets &amp; Adding a column
############################################
#Load sentiment word lists
hu.liu.pos = scan('C:/Assignment/positive-words.txt', what='character', comment.char=';')
hu.liu.neg = scan('C:/Assignment/negative-words.txt', what='character', comment.char=';')
#Add words to list
pos.words = hu.liu.pos
neg.words = hu.liu.neg
#Import 2 csv
DatasetFacebook <- read.csv("C:/Assignment/FacebookTweets.csv")
DatasetFacebook$text<-as.factor(DatasetFacebook$text)
#Score all tweets from Facebook
Facebook.scores = score.sentiment(DatasetFacebook$text, pos.words,neg.words, .progress='text')
#Export scores to csv file
path<-"C:/Assignment/"
write.csv(Facebook.scores,file=paste(path,"FacebookScores.csv",sep=""),row.names=TRUE)
Facebook.scores$Team = 'Facebook'
#############################
# Visualizing
#############################
library(ggplot2)
hist(Facebook.scores$score)
qplot(Facebook.scores$score)
#################################
# Comparing 2 datasets
#################################
all.scores = rbind(Facebook.scores)
ggplot(data=all.scores) + # ggplot works on data.frames, always
geom_bar(mapping=aes(x=score, fill=Team), binwidth=1) +
facet_grid(Team~.) + # make a separate plot for each hashtag
theme_bw() + scale_fill_brewer() # plain display, nicer colors
#get Get Authentication of twitter
require(twitteR)
clear
#get Get Authentication of twitter
require(twitteR)
install.packages("twitter")
install.packages("twitteR")
#get Get Authentication of twitter
require(twitteR)
library(ROAuth)
library(plyr)
install.packages("plyr")
install.packages("stringr")
install.packages("ggplot2")
#get Get Authentication of twitter
require(twitteR)
library(ROAuth)
library(plyr)
library(stringr)
library(ggplot2)
download.file(url="http://curl.haxx.se/ca/cacert.pem", destfile="cacert.pem")
requestURL <-"https://api.twitter.com/oauth/request_token"
accessURL <- "https://api.twitter.com/oauth/access_token"
authURL <- "https://api.twitter.com/oauth/authorize"
consumerKey = "02Ph1HDIG49W0whP76pzEbA5k"
consumerSecret = "O4yG0VUPz7Mo3l30YGQTPpC2DrGVKyotZqPezLQv2bBtIjdNZV"
Cred <- OAuthFactory$new(consumerKey=consumerKey,
consumerSecret=consumerSecret,
requestURL=requestURL,
accessURL=accessURL,
authURL=authURL)
Cred$handshake(cainfo = system.file("CurlSSL", "cacert.pem", package = "RCurl") )
# Comments: This is a very important step; you need to copy the url and #paste to internet browser, then copy the code to R, follow the video to #complete this step.
save(Cred, file="twitter authentication.Rdata")
registerTwitterOAuth(Cred)
############################################################
# Chunk  - 2 - Twitter Scrape  #Marriott #Hilton #
############################################################
Path = 'C:/MyHWP/TP/20141020/CBA1C05 - Social Media Analytics/Assignment/'
Marriott.list <- searchTwitter('#Marriott', n=1000, cainfo="cacert.pem")
# Comments: Mining 1000 tweets of ???Marriott ???, you might not get 1000 tweets
Marriott.df = twListToDF(Marriott.list)
write.csv(Marriott.df, file=paste(Path,"MarriottTweets.csv",sep=""), row.names=F)
# Comments: export data to your own path
Hilton.list <- searchTwitter('#Hilton', n=1000, cainfo="cacert.pem")
# Comments: Mining 1000 tweets of ???Hilton???
Hilton.df = twListToDF(Hilton.list)
write.csv(Hilton.df, file=paste(Path,"HiltonTweets.csv",sep=""), row.names=F)
# Comments: export data to your own path
###############################
# Sentiment Function
###############################
library (plyr)
library (stringr)
score.sentiment = function(sentences, pos.words, neg.words, .progress='none')
{
require(plyr)
require(stringr)
scores=laply(sentences, function(sentence, pos.words, neg.words){
sentence = gsub('[[:punct:]]', '', sentence)
sentence = gsub('[[:cntrl:]]', '', sentence)
sentence = gsub('\\d+', '', sentence)
sentence = tolower(sentence)
word.list = str_split(sentence, '\\s+')
words = unlist(word.list)
pos.matches = match(words, pos.words)
neg.matches = match(words, neg.words)
pos.matches = !is.na(pos.matches)
neg.matches = !is.na(neg.matches)
score = sum(pos.matches) - sum(neg.matches)
return(score)
}, pos.words, neg.words, .progress=.progress)
scores.df = data.frame(score=scores, text=sentences)
return(scores.df)
}
############################################
# Scoring Tweets &amp; Adding a column
############################################
#Load sentiment word lists
hu.liu.pos = scan('C:/MyHWP/TP/20141020/CBA1C05 - Social Media Analytics/Assignment/positive-words.txt', what='character', comment.char=';')
hu.liu.neg = scan('C:/MyHWP/TP/20141020/CBA1C05 - Social Media Analytics/Assignment/negative-words.txt', what='character', comment.char=';')
#Add words to list
pos.words = hu.liu.pos
neg.words = hu.liu.neg
#Import 2 csv
DatasetMarriott <- read.csv("C:/MyHWP/TP/20141020/CBA1C05 - Social Media Analytics/Assignment/MarriottTweets.csv")
DatasetMarriott$text<-as.factor(DatasetMarriott$text)
DatasetHilton <- read.csv("C:/MyHWP/TP/20141020/CBA1C05 - Social Media Analytics/Assignment/HiltonTweets.csv")
DatasetHilton$text<-as.factor(DatasetHilton$text)
#Score all tweets from Marriott Hotel
Marriott.scores = score.sentiment(DatasetMarriott$text, pos.words,neg.words, .progress='text')
#Score all tweets from Hilton Hotel
Hilton.scores = score.sentiment(DatasetHilton$text, pos.words,neg.words, .progress='text')
#Export scores to csv file
path<-"C:/MyHWP/TP/20141020/CBA1C05 - Social Media Analytics/Assignment/"
write.csv(Marriott.scores,file=paste(path,"MarriottScores.csv",sep=""),row.names=TRUE)
write.csv(Hilton.scores,file=paste(path,"HiltonScores.csv",sep=""),row.names=TRUE)
Marriott.scores$Team = 'Marriott'
Hilton.scores$Team = 'Hilton'
#############################
# Visualizing
#############################
library(ggplot2)
hist(Marriott.scores$score)
qplot(Marriott.scores$score)
qplot(Marriott.scores$score, binwidth = 4)
qplot(Marriott.scores$score, binwidth = 10)
qplot(Marriott.scores$score, binwidth = 20)
qplot(Marriott.scores$score, binwidth = 1)
qplot(Marriott.scores$score, binwidth = 2)
qplot(Marriott.scores$score, binwidth = 1)
qplot(Marriott.scores$score, binwidth = 0.5)
qplot(Marriott.scores$score, binwidth = 1)
qplot(Marriott.scores$score, binwidth = 0.5)
hist(Hilton.scores$score)
qplot(Hilton.scores$score)
qplot(Hilton.scores$score, binwidth = 0.5)
hist(Hilton.scores$score)
qplot(Hilton.scores$score, binwidth = 0.5)
#################################
# Comparing 2 datasets
#################################
all.scores = rbind(Marriott.scores, Hilton.scores)
table(all.scores$score,all.scores$Team)
ggplot(data=all.scores) + # ggplot works on data.frames, always
geom_bar(mapping=aes(x=score, fill=Team), binwidth=1) +
facet_grid(Team~.) + # make a separate plot for each hashtag
theme_bw() + scale_fill_brewer() # plain display, nicer colors
hlp()
help()
help(demo)
q()
ls()
rm()
rm(x)
help(rm)
vector
list
factor
array
library(rpart)
CRAN
library(shiny)
install.packages("shinyapp")
install.packages("shinyapps")
install.packages(c("caret", "pROC", "rpart", "gbm", "ggplot2",
"kernlab", "partykit", "lubridate"),
repos = "http://cran.r-project.org",
dependencies = c("Depends", "Imports", "Suggests"))
shiny::runApp('C:/MyHWP/MOOC/CourseWork/DDP/GeraldYeo')
install.packages("devtools")
library(devtools)
install.packages("slidify","ramnathv")
install.github("slidify","ramnathv")
library(slidify)
install.packages("slidify", lib="C:/Program Files/R/R-3.1.3/library")
library(slidify)
install_github('slidify','ramnathv')
install_github('slidifyLibraries','ramnathv')
library(slidify)
setwd("C:/MyHWP/MOOC/CourseWork/DDP/HWP")
author("USDSGD_Analysis")
slidify("index.Rmd")
browseURL("index.html")
